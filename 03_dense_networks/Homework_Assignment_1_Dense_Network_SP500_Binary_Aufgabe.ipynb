{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003e5d42",
   "metadata": {
    "id": "003e5d42"
   },
   "source": [
    "# Dense Networks ¬∑ SP500 Next‚ÄëDay Direction (Binary Classification)\n",
    "\n",
    "**Objective**: Predict tomorrow's SP500 move (up/down) using **lagged cross‚Äësectional stock returns** with a **Dense (MLP) network**.\n",
    "\n",
    "You can run this notebook in **Google Colab**. It includes two ready experiments:\n",
    "- **A:** Few stocks, many lags  \n",
    "- **B:** Many stocks, few lags\n",
    "\n",
    "üá¨üáß Note: This exercise belongs to the Dense Networks topic. Students compare how the number of lags and the number of stocks affect the model‚Äôs stability and performance.\n",
    "\n",
    "üá∑üá∫ –ü–æ–¥—Å–∫–∞–∑–∫–∞: —ç—Ç–æ –ø—Ä–∞–∫—Ç–∏–∫—É–º –¥–ª—è —Ç–µ–º—ã *Dense Networks*. –°—Ç—É–¥–µ–Ω—Ç—ã —Å—Ä–∞–≤–Ω–∏–≤–∞—é—Ç –≤–ª–∏—è–Ω–∏–µ **—á–∏—Å–ª–∞ –ª–∞–≥–æ–≤** –∏ **—á–∏—Å–ª–∞ –∞–∫—Ü–∏–π** –Ω–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3ea89",
   "metadata": {
    "id": "2ac3ea89"
   },
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "e7e38ed6",
   "metadata": {
    "id": "e7e38ed6",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:46.311446Z",
     "start_time": "2025-11-10T11:30:46.309805Z"
    }
   },
   "source": [
    "# If running in Colab:\n",
    "# !pip -q install yfinance pandas numpy scikit-learn torch==2.4.1 matplotlib"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "314ffb0d",
   "metadata": {
    "id": "314ffb0d",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:46.381271Z",
     "start_time": "2025-11-10T11:30:46.374755Z"
    }
   },
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(7)\n",
    "np.random.seed(7)\n",
    "\n",
    "print(\"Torch:\", torch.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.0+cu128\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "fd1f1308",
   "metadata": {
    "id": "fd1f1308"
   },
   "source": [
    "## 1) Data: choose one of the options\n",
    "\n",
    "### Option 1 ‚Äî Download with `yfinance` (easiest in Colab)\n",
    "- Includes **SPY** for market proxy and a basket of large‚Äëcap tickers."
   ]
  },
  {
   "cell_type": "code",
   "id": "2792d992",
   "metadata": {
    "id": "2792d992",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:48.099593Z",
     "start_time": "2025-11-10T11:30:46.476071Z"
    }
   },
   "source": [
    "use_yfinance = True  # set to False if you upload your own CSV of returns\n",
    "\n",
    "tickers_all = [\n",
    "    \"AAPL\",\"MSFT\",\"NVDA\",\"AMZN\",\"GOOG\",\"META\",\"BRK-B\",\"TSLA\",\"AVGO\",\"LLY\",\n",
    "    \"V\",\"JPM\",\"XOM\",\"UNH\",\"MA\",\"HD\",\"PG\",\"COST\",\"ADBE\",\"NFLX\",\n",
    "    \"PEP\",\"CRM\",\"KO\",\"MRK\",\"ABBV\"\n",
    "]\n",
    "spy = \"SPY\"\n",
    "start_date = \"2012-01-01\"\n",
    "end_date = None  # or e.g. \"2025-01-01\"\n",
    "\n",
    "if use_yfinance:\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        data = yf.download([spy] + tickers_all, start=start_date, end=end_date, auto_adjust=True, progress=False)[\"Close\"]\n",
    "        data = data.dropna(how=\"all\")\n",
    "        data = data.asfreq(\"B\").ffill()  # align to business days\n",
    "        rets = data.pct_change().dropna()\n",
    "        #rets.columns = [c.replace(\" \", \"_\").replace(\"-\", \"_\") for c in rets.columns]\n",
    "        #tickers_all = [t.replace(\" \", \"_\").replace(\"-\", \"_\") for t in tickers_all]\n",
    "\n",
    "        spy_col = spy\n",
    "        print(\"Data downloaded. Shape:\", rets.shape)\n",
    "    except Exception as e:\n",
    "        print(\"yfinance failed:\", e)\n",
    "        use_yfinance = False\n",
    "else:\n",
    "    print(\"Set use_yfinance=True to auto-download, or upload your own CSV in the next cell.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded. Shape: (3352, 26)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "75567bc5",
   "metadata": {
    "id": "75567bc5"
   },
   "source": [
    "### Option 2 ‚Äî Upload your own **returns** CSV\n",
    "- Must contain **SPY** column (market proxy) and several stock columns\n",
    "- Index must be a **date** (parseable)"
   ]
  },
  {
   "cell_type": "code",
   "id": "5f7f1c72",
   "metadata": {
    "id": "5f7f1c72",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:48.165222Z",
     "start_time": "2025-11-10T11:30:48.161878Z"
    }
   },
   "source": [
    "# If not using yfinance, upload your own daily RETURNS CSV with columns: SPY, AAPL, MSFT, ...\n",
    "# Example:\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# rets = pd.read_csv(list(uploaded.keys())[0], index_col=0, parse_dates=True)\n",
    "# spy_col = \"SPY\""
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "88cef556",
   "metadata": {
    "id": "88cef556",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:48.227662Z",
     "start_time": "2025-11-10T11:30:48.218906Z"
    }
   },
   "source": [
    "assert 'rets' in globals(), \"Please prepare `rets` (returns DataFrame) and `spy_col`.\"\n",
    "assert spy_col in rets.columns, f\"`{spy_col}` column required.\"\n",
    "rets = rets.sort_index()\n",
    "rets.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticker          AAPL      ABBV      ADBE      AMZN      AVGO     BRK-B  \\\n",
       "Date                                                                     \n",
       "2013-01-03 -0.012622 -0.008257 -0.015389  0.004547  0.005224  0.004507   \n",
       "2013-01-04 -0.027855 -0.012633  0.010066  0.002592 -0.006420  0.002457   \n",
       "2013-01-07 -0.005882  0.002035 -0.004983  0.035925 -0.005539 -0.004262   \n",
       "2013-01-08  0.002691 -0.021764  0.005272 -0.007748 -0.006807  0.003852   \n",
       "2013-01-09 -0.015629  0.005636  0.013634 -0.000113  0.022118 -0.005223   \n",
       "\n",
       "Ticker          COST       CRM      GOOG        HD  ...      MSFT      NFLX  \\\n",
       "Date                                                ...                       \n",
       "2013-01-03  0.010251 -0.014372  0.000581 -0.002836  ... -0.013396  0.049777   \n",
       "2013-01-04 -0.003220  0.005335  0.019760 -0.001896  ... -0.018716 -0.006315   \n",
       "2013-01-07 -0.007733 -0.003714 -0.004363 -0.005382  ... -0.001870  0.033549   \n",
       "2013-01-08 -0.001875  0.005859 -0.001974  0.006047  ... -0.005245 -0.020565   \n",
       "2013-01-09  0.000494  0.010943  0.006573 -0.000791  ...  0.005650 -0.012865   \n",
       "\n",
       "Ticker          NVDA       PEP        PG       SPY      TSLA       UNH  \\\n",
       "Date                                                                     \n",
       "2013-01-03  0.000786  0.000433 -0.006341 -0.002259 -0.016685 -0.046755   \n",
       "2013-01-04  0.032993  0.001442  0.002031  0.004392 -0.010642  0.001923   \n",
       "2013-01-07 -0.028897 -0.000144 -0.006803 -0.002733 -0.001744  0.000000   \n",
       "2013-01-08 -0.021926  0.003024 -0.001603 -0.002878 -0.019220 -0.013246   \n",
       "2013-01-09 -0.022418  0.005024  0.005401  0.002542 -0.001187  0.018872   \n",
       "\n",
       "Ticker             V       XOM  \n",
       "Date                            \n",
       "2013-01-03  0.000772 -0.001803  \n",
       "2013-01-04  0.008167  0.004630  \n",
       "2013-01-07  0.007144 -0.011578  \n",
       "2013-01-08  0.009310  0.006255  \n",
       "2013-01-09  0.015248 -0.003843  \n",
       "\n",
       "[5 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AVGO</th>\n",
       "      <th>BRK-B</th>\n",
       "      <th>COST</th>\n",
       "      <th>CRM</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>HD</th>\n",
       "      <th>...</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NFLX</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>PEP</th>\n",
       "      <th>PG</th>\n",
       "      <th>SPY</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>UNH</th>\n",
       "      <th>V</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.012622</td>\n",
       "      <td>-0.008257</td>\n",
       "      <td>-0.015389</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.010251</td>\n",
       "      <td>-0.014372</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.002836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013396</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>-0.006341</td>\n",
       "      <td>-0.002259</td>\n",
       "      <td>-0.016685</td>\n",
       "      <td>-0.046755</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>-0.001803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.027855</td>\n",
       "      <td>-0.012633</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>-0.006420</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>-0.003220</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.019760</td>\n",
       "      <td>-0.001896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>-0.006315</td>\n",
       "      <td>0.032993</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>-0.010642</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>0.004630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>-0.005882</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>0.035925</td>\n",
       "      <td>-0.005539</td>\n",
       "      <td>-0.004262</td>\n",
       "      <td>-0.007733</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>-0.004363</td>\n",
       "      <td>-0.005382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001870</td>\n",
       "      <td>0.033549</td>\n",
       "      <td>-0.028897</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>-0.006803</td>\n",
       "      <td>-0.002733</td>\n",
       "      <td>-0.001744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>-0.011578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>0.002691</td>\n",
       "      <td>-0.021764</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>-0.007748</td>\n",
       "      <td>-0.006807</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005245</td>\n",
       "      <td>-0.020565</td>\n",
       "      <td>-0.021926</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>-0.001603</td>\n",
       "      <td>-0.002878</td>\n",
       "      <td>-0.019220</td>\n",
       "      <td>-0.013246</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.006255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-09</th>\n",
       "      <td>-0.015629</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.013634</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>-0.005223</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.010943</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>-0.022418</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>0.018872</td>\n",
       "      <td>0.015248</td>\n",
       "      <td>-0.003843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "0c626189",
   "metadata": {
    "id": "0c626189"
   },
   "source": [
    "## 2) Target and Base Features"
   ]
  },
  {
   "cell_type": "code",
   "id": "bf9fb250",
   "metadata": {
    "id": "bf9fb250",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:48.369646Z",
     "start_time": "2025-11-10T11:30:48.355666Z"
    }
   },
   "source": [
    "# Target = tomorrow's SP500/market sign\n",
    "y = (rets[spy_col].shift(-1) > 0).astype(int)\n",
    "\n",
    "# Base cross-sectional features (exclude SPY to avoid leakage)\n",
    "X_base = rets.drop(columns=[spy_col])\n",
    "X_base.head(), y.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Ticker          AAPL      ABBV      ADBE      AMZN      AVGO     BRK-B  \\\n",
       " Date                                                                     \n",
       " 2013-01-03 -0.012622 -0.008257 -0.015389  0.004547  0.005224  0.004507   \n",
       " 2013-01-04 -0.027855 -0.012633  0.010066  0.002592 -0.006420  0.002457   \n",
       " 2013-01-07 -0.005882  0.002035 -0.004983  0.035925 -0.005539 -0.004262   \n",
       " 2013-01-08  0.002691 -0.021764  0.005272 -0.007748 -0.006807  0.003852   \n",
       " 2013-01-09 -0.015629  0.005636  0.013634 -0.000113  0.022118 -0.005223   \n",
       " \n",
       " Ticker          COST       CRM      GOOG        HD  ...       MRK      MSFT  \\\n",
       " Date                                                ...                       \n",
       " 2013-01-03  0.010251 -0.014372  0.000581 -0.002836  ...  0.023947 -0.013396   \n",
       " 2013-01-04 -0.003220  0.005335  0.019760 -0.001896  ... -0.008504 -0.018716   \n",
       " 2013-01-07 -0.007733 -0.003714 -0.004363 -0.005382  ...  0.003574 -0.001870   \n",
       " 2013-01-08 -0.001875  0.005859 -0.001974  0.006047  ...  0.001425 -0.005245   \n",
       " 2013-01-09  0.000494  0.010943  0.006573 -0.000791  ...  0.009720  0.005650   \n",
       " \n",
       " Ticker          NFLX      NVDA       PEP        PG      TSLA       UNH  \\\n",
       " Date                                                                     \n",
       " 2013-01-03  0.049777  0.000786  0.000433 -0.006341 -0.016685 -0.046755   \n",
       " 2013-01-04 -0.006315  0.032993  0.001442  0.002031 -0.010642  0.001923   \n",
       " 2013-01-07  0.033549 -0.028897 -0.000144 -0.006803 -0.001744  0.000000   \n",
       " 2013-01-08 -0.020565 -0.021926  0.003024 -0.001603 -0.019220 -0.013246   \n",
       " 2013-01-09 -0.012865 -0.022418  0.005024  0.005401 -0.001187  0.018872   \n",
       " \n",
       " Ticker             V       XOM  \n",
       " Date                            \n",
       " 2013-01-03  0.000772 -0.001803  \n",
       " 2013-01-04  0.008167  0.004630  \n",
       " 2013-01-07  0.007144 -0.011578  \n",
       " 2013-01-08  0.009310  0.006255  \n",
       " 2013-01-09  0.015248 -0.003843  \n",
       " \n",
       " [5 rows x 25 columns],\n",
       " Date\n",
       " 2013-01-03    1\n",
       " 2013-01-04    0\n",
       " 2013-01-07    0\n",
       " 2013-01-08    1\n",
       " 2013-01-09    1\n",
       " Freq: B, Name: SPY, dtype: int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "8d8575c9",
   "metadata": {
    "id": "8d8575c9"
   },
   "source": [
    "## 3) Helper: build lagged features"
   ]
  },
  {
   "cell_type": "code",
   "id": "b2244a73",
   "metadata": {
    "id": "b2244a73",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:48.504560Z",
     "start_time": "2025-11-10T11:30:48.500818Z"
    }
   },
   "source": [
    "def build_lagged_features(df: pd.DataFrame, n_lags: int) -> pd.DataFrame:\n",
    "    cols = {}\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        lagged = df.shift(lag).add_suffix(f\"_lag{lag}\")\n",
    "        cols[lag] = lagged\n",
    "    X = pd.concat([cols[lag] for lag in cols], axis=1)\n",
    "    return X\n",
    "\n",
    "# Quick test\n",
    "_ = build_lagged_features(X_base.iloc[:10], 3)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "bb3b28a2",
   "metadata": {
    "id": "bb3b28a2"
   },
   "source": [
    "## 4) PyTorch dataset & model"
   ]
  },
  {
   "cell_type": "code",
   "id": "c94547b2",
   "metadata": {
    "id": "c94547b2",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:48.620833Z",
     "start_time": "2025-11-10T11:30:48.617213Z"
    }
   },
   "source": [
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.float32).reshape(-1, 1)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden=(64, 32), p_dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last = in_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(last, h), nn.ReLU(), nn.Dropout(p_dropout)]\n",
    "            last = h\n",
    "        layers += [nn.Linear(last, 1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # logits"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "a929bc35",
   "metadata": {
    "id": "a929bc35",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:48.663388Z",
     "start_time": "2025-11-10T11:30:48.658825Z"
    }
   },
   "source": [
    "def train_model(X_train, y_train, X_val, y_val, epochs=50, batch_size=128, lr=1e-3, weight_decay=1e-4, hidden=(64,32)):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_val_s   = scaler.transform(X_val)\n",
    "\n",
    "    train_ds = TabDataset(X_train_s, y_train)\n",
    "    val_ds   = TabDataset(X_val_s,   y_val)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    model = MLP(in_dim=X_train.shape[1], hidden=hidden, p_dropout=0.1)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "    patience, patience_left = 8, 8\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(xb)\n",
    "        train_loss /= len(train_ds)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            preds = []\n",
    "            ys = []\n",
    "            for xb, yb in val_loader:\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                val_loss += loss.item() * len(xb)\n",
    "                preds.append(torch.sigmoid(logits).cpu().numpy())\n",
    "                ys.append(yb.cpu().numpy())\n",
    "            val_loss /= len(val_ds)\n",
    "        if val_loss < best_val - 1e-5:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience_left = patience\n",
    "        else:\n",
    "            patience_left -= 1\n",
    "            if patience_left <= 0:\n",
    "                # early stop\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model, scaler"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "203e3736",
   "metadata": {
    "id": "203e3736",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:48.715580Z",
     "start_time": "2025-11-10T11:30:48.712803Z"
    }
   },
   "source": [
    "def evaluate_model(model, scaler, X, y, threshold=0.5, label=\"VAL\"):\n",
    "    Xs = scaler.transform(X).astype(np.float32)\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.from_numpy(Xs))\n",
    "        probs = torch.sigmoid(logits).numpy().ravel()\n",
    "\n",
    "    y_pred = (probs >= threshold).astype(int)\n",
    "    acc  = accuracy_score(y, y_pred)\n",
    "    bacc = balanced_accuracy_score(y, y_pred)\n",
    "    try:\n",
    "        roc  = roc_auc_score(y, probs)\n",
    "    except ValueError:\n",
    "        roc = np.nan\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "    print(f\"[{label}] Accuracy={acc:.3f} | BalancedAcc={bacc:.3f} | ROC-AUC={roc:.3f}\")\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    return {\"acc\": acc, \"bacc\": bacc, \"roc\": roc, \"cm\": cm, \"probs\": probs, \"pred\": y_pred}"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "e3fd560a",
   "metadata": {
    "id": "e3fd560a"
   },
   "source": [
    "## 5) Time split: train / val / test"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5a42fe2251593287"
  },
  {
   "cell_type": "code",
   "id": "dd1d66c4",
   "metadata": {
    "id": "dd1d66c4",
    "ExecuteTime": {
     "end_time": "2025-11-10T11:30:48.767145Z",
     "start_time": "2025-11-10T11:30:48.764750Z"
    }
   },
   "source": [
    "def time_split_idx(n, train_frac=0.7, val_frac=0.15):\n",
    "    train_end = int(n * train_frac)\n",
    "    val_end   = int(n * (train_frac + val_frac))\n",
    "    return slice(0, train_end), slice(train_end, val_end), slice(val_end, n)"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "c25d07c8",
   "metadata": {
    "id": "c25d07c8"
   },
   "source": [
    "## 6) Experiments A & B"
   ]
  },
  {
   "cell_type": "code",
   "id": "b8a8e76b",
   "metadata": {
    "id": "b8a8e76b",
    "ExecuteTime": {
     "end_time": "2025-11-10T13:38:00.108312Z",
     "start_time": "2025-11-10T13:37:58.196687Z"
    }
   },
   "source": [
    "def run_experiment(name, stock_list, n_lags, hidden=(64,32), epochs=60):\n",
    "    print(f\"\\n=== Experiment {name}: stocks={len(stock_list)}, lags={n_lags} ===\")\n",
    "\n",
    "    # Validate and filter stock_list to only include available columns\n",
    "    available_stocks = [stock for stock in stock_list if stock in X_base.columns]\n",
    "    missing_stocks = [stock for stock in stock_list if stock not in X_base.columns]\n",
    "\n",
    "    if missing_stocks:\n",
    "        print(f\"Warning: The following stocks are not available and will be skipped: {missing_stocks}\")\n",
    "\n",
    "    if not available_stocks:\n",
    "        print(f\"Error: None of the requested stocks are available in X_base\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    X_cs = X_base[available_stocks]\n",
    "    X = build_lagged_features(X_cs, n_lags)\n",
    "    y_aligned = y.loc[X.index]\n",
    "\n",
    "    # drop NA from shifts\n",
    "    mask = X.notna().all(axis=1) & y_aligned.notna()\n",
    "    X = X[mask]\n",
    "    y_arr = y_aligned[mask].values\n",
    "\n",
    "    n = len(X)\n",
    "    tr, va, te = time_split_idx(n, 0.7, 0.15)\n",
    "    X_train, y_train = X.iloc[tr].values, y_arr[tr]\n",
    "    X_val,   y_val   = X.iloc[va].values, y_arr[va]\n",
    "    X_test,  y_test  = X.iloc[te].values, y_arr[te]\n",
    "\n",
    "    model, scaler = train_model(X_train, y_train, X_val, y_val, epochs=epochs, hidden=hidden)\n",
    "    eval_val = evaluate_model(model, scaler, X_val, y_val, label=f\"{name}-VAL\")\n",
    "    eval_te  = evaluate_model(model, scaler, X_test, y_test, label=f\"{name}-TEST\")\n",
    "\n",
    "    return {\"name\": name, \"eval_val\": eval_val, \"eval_test\": eval_te}\n",
    "\n",
    "# Define stock subsets\n",
    "few_stocks  = [\"AAPL\",\"MSFT\",\"NVDA\",\"AMZN\",\"GOOG\"]\n",
    "many_stocks = tickers_all if 'tickers_all' in globals() else list(X_base.columns)[:20]\n",
    "\n",
    "# Run two contrasting experiments\n",
    "res_A = run_experiment(\"A (few stocks, many lags)\", stock_list=few_stocks,  n_lags=15, hidden=(256,128))\n",
    "res_B = run_experiment(\"B (many stocks, few lags)\", stock_list=many_stocks, n_lags=5, hidden=(128,64))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment A (few stocks, many lags): stocks=5, lags=15 ===\n",
      "[A (few stocks, many lags)-VAL] Accuracy=0.499 | BalancedAcc=0.516 | ROC-AUC=0.522\n",
      "Confusion matrix:\n",
      " [[ 54 210]\n",
      " [ 41 196]]\n",
      "[A (few stocks, many lags)-TEST] Accuracy=0.547 | BalancedAcc=0.506 | ROC-AUC=0.502\n",
      "Confusion matrix:\n",
      " [[ 40 179]\n",
      " [ 48 234]]\n",
      "\n",
      "=== Experiment B (many stocks, few lags): stocks=25, lags=5 ===\n",
      "[B (many stocks, few lags)-VAL] Accuracy=0.462 | BalancedAcc=0.488 | ROC-AUC=0.506\n",
      "Confusion matrix:\n",
      " [[ 23 244]\n",
      " [ 26 209]]\n",
      "[B (many stocks, few lags)-TEST] Accuracy=0.543 | BalancedAcc=0.491 | ROC-AUC=0.534\n",
      "Confusion matrix:\n",
      " [[ 20 199]\n",
      " [ 31 253]]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "### üß© Concept Notes\n",
    "\n",
    "#### **Bias‚ÄìVariance Trade-off**\n",
    "When we increase model complexity ‚Äî for example, by adding more **lags**, **neurons**, or **layers** ‚Äî the model can fit the training data more precisely but may lose its ability to generalize.  \n",
    "This balance between **bias** (systematic error) and **variance** (sensitivity to noise) is central to all machine learning:\n",
    "\n",
    "| Scenario | Bias | Variance | Description |\n",
    "|-----------|------|-----------|--------------|\n",
    "| Too simple model (few lags, small net) | high | low | underfitting ‚Äî misses true patterns |\n",
    "| Too complex model (many lags, deep net) | low | high | overfitting ‚Äî memorizes noise |\n",
    "| Balanced model | moderate | moderate | captures signal, ignores noise |\n",
    "\n",
    "> üí° In this exercise: adding too many lags can make the model memorize daily fluctuations instead of learning meaningful temporal structure.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Cross-sectional Breadth**\n",
    "Cross-sectional means ‚Äúacross many assets at the same time.‚Äù  \n",
    "If **lags** add *temporal depth*, then **breadth** adds *market width* ‚Äî the diversity of stocks used as simultaneous features.\n",
    "\n",
    "| Scenario | What it means | Effect |\n",
    "|-----------|----------------|---------|\n",
    "| Few stocks, many lags | Focus on temporal behavior of each stock | Captures time-series structure but loses market context |\n",
    "| Many stocks, few lags | Focus on market snapshot at each date | Captures cross-sectional structure but adds noise |\n",
    "\n",
    "> üí° Example: if the market index rises because only tech stocks surge while others fall, this is a **cross-sectional signal** ‚Äî it can‚Äôt be seen from SP500 alone.\n"
   ],
   "metadata": {
    "id": "GOlyWlm2tmLl"
   },
   "id": "GOlyWlm2tmLl"
  },
  {
   "cell_type": "markdown",
   "id": "9f14fbfb",
   "metadata": {
    "id": "9f14fbfb"
   },
   "source": [
    "## 7) Discuss\n",
    "\n",
    "EN:\n",
    "- **Bias‚ÄìVariance Trade-off**: Increasing the number of lags (time dimension) while keeping the same number of stocks expands the feature space ‚Äî this raises the risk of overfitting, especially with shorter time series.\n",
    "\n",
    "- **Cross-sectional Breadth**: Using more stocks with fewer lags adds cross-sectional information (market dispersion on a given day) but may introduce additional noise.\n",
    "\n",
    "- **Metrics ‚âà 0.50‚Äì0.55** on test data are typical for a clean setup without data leakage.\n",
    "If ROC-AUC < 0.5, the model has learned a weak **anti-signal** ‚Äî try inverting the target or adjusting feature definitions.\n",
    "\n",
    "\n",
    "RU:\n",
    "- **Bias‚ÄìVariance trade‚Äëoff**: –±–æ–ª—å—à–µ –ª–∞–≥–æ–≤ (–≤—Ä–µ–º–µ–Ω–∏) –ø—Ä–∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —á–∏—Å–ª–µ –∞–∫—Ü–∏–π —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ ‚Üí —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ä—è–¥–∞—Ö.  \n",
    "- **Cross‚Äësectional breadth**: –±–æ–ª—å—à–µ –∞–∫—Ü–∏–π –ø—Ä–∏ –º–∞–ª–æ–º —á–∏—Å–ª–µ –ª–∞–≥–æ–≤ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–ø–µ—Ä–µ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä—ã–Ω–∫–∞ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –¥–µ–Ω—å), –Ω–æ –º–æ–∂–µ—Ç —É—Å–∏–ª–∏–≤–∞—Ç—å —à—É–º.  \n",
    "- **–ú–µ—Ç—Ä–∏–∫–∏ ‚âà 0.50‚Äì0.55** –Ω–∞ —Ç–µ—Å—Ç–µ ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è ¬´—á–µ—Å—Ç–Ω–æ–π¬ª –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –±–µ–∑ —É—Ç–µ—á–∫–∏. –ï—Å–ª–∏ ROC‚ÄëAUC < 0.5 ‚Äî —ç—Ç–æ **–∞–Ω—Ç–∏‚Äë—Å–∏–≥–Ω–∞–ª**; –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ä–æ–≥ –∏–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
